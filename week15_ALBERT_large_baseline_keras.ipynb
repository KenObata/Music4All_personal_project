{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenObata/Music4All_personal_project/blob/main/week15_ALBERT_large_baseline_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8WVxEoWZG0"
      },
      "source": [
        "## Week15: This notebook uses Pre-Trained word matrix-> SMOTE -> undersample by EDA -> append to word vectors. -> using Word2Vec. After that I apply SMOTE to balance out. \n",
        "Added task: Grid Search for best parameter in SVM.\n",
        "\n",
        "Situation: English only (=multi-class).\n",
        "Split: StratifiedKfold.\n",
        "Reference: https://github.com/jasonwei20/eda_nlp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWL5DlwVTHgV"
      },
      "source": [
        "### set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fdw4QzS4FD",
        "outputId": "773d8b5e-58f3-438b-9027-ade1324a61ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1d5F3EmWPVWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "\n",
        "from skmultilearn.model_selection import IterativeStratification   \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "def get_balanced_accuracy(model, McNemar, is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning):\n",
        "  test_y = test.map(map_func_only_y)\n",
        "  y_category=np.zeros((TEST_SIZE, ))\n",
        "  counter=0\n",
        "  for label_tensor in test_y.take(len(test_y)):\n",
        "    y_test = np.argmax(label_tensor, axis=1)\n",
        "    for label in y_test:\n",
        "      y_category[counter]=label\n",
        "      counter+=1\n",
        "\n",
        "  X_test, y_test = test.map(map_func_only_X), y_category\n",
        "  y_predict_test = np.asarray(model.predict(X_test))\n",
        "  y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "  print(classification_report(y_test, y_predict_test) )\n",
        "  print(balanced_accuracy_score(y_test, y_predict_test))\n",
        "\n",
        "  McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)] = []\n",
        "  for ground_truh, pred in zip(y_test, y_predict_test):\n",
        "        if ground_truh==pred:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(True)\n",
        "        else:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(False)\n",
        "  with open(DIR+ \"ALBERT_large_log.txt\", \"a\") as f:\n",
        "    print(\"======================================\", file=f)\n",
        "    print(\"is_fine_tuning?:\", is_fine_tuning, \"drop_out_rate: \", drop_out_rate, \"learning_rate_transfer_learning: \", learning_rate_transfer_learning,\n",
        "          \"learning_rate_fine_tuning: \", learning_rate_fine_tuning, file=f)\n",
        "    print(classification_report(y_test, y_predict_test) , file=f)\n",
        "    print(balanced_accuracy_score(y_test, y_predict_test), file=f)\n",
        "\n",
        "  return balanced_accuracy_score(y_test, y_predict_test), McNemar"
      ],
      "metadata": {
        "id": "K6VTlTxg8JVQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfNJqYBfjD"
      },
      "source": [
        "### Data Preparation(Kfold split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbT7Qs4whnTX"
      },
      "source": [
        "Create dataframe for Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Le3tiKjOOp19",
        "outputId": "383d75ed-20a5-437a-d170-ab2d681d7b81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                id             genres lang  \\\n",
              "0               0  0009fFIM1eYThaPg                pop   en   \n",
              "1               1  00P2bHdWFkghmDqz               soul   en   \n",
              "2               2  00b6fV3nx5z2b8Ls                pop   en   \n",
              "3               3  013QDoTqbexEwkHr                pop   en   \n",
              "4               4  01EKNot8qVgZpKM7               rock   en   \n",
              "...           ...               ...                ...  ...   \n",
              "13535       13535  zzT504Z94j1IAuc3         indie rock   en   \n",
              "13536       13536  zzgS4ZqyswamEWNj                pop   en   \n",
              "13537       13537  zzx8CWdM7qkxKQpC         indie rock   en   \n",
              "13538       13538  zzz0n04uuTUA7fNh                pop   en   \n",
              "13539       13539  zzzj3LYaZtYtbzSr  singer-songwriter   en   \n",
              "\n",
              "                                                   lyric  number_of_line  \n",
              "0      a sunny day so I got nowhere to hide Not a clo...              91  \n",
              "1      Tell me a tale that always was Sing me a song ...              36  \n",
              "2      A buh A buh You went to school to learn girl T...              74  \n",
              "3      like a conversation where stops to breathe Is ...              20  \n",
              "4      Say the words I cannot say Say them on another...              31  \n",
              "...                                                  ...             ...  \n",
              "13535  think what afraid of come in you know been mad...              18  \n",
              "13536  Oh yeah yeah Last night I took a walk in the s...              75  \n",
              "13537  Innocence it come easy in a sense it never wil...              34  \n",
              "13538  Girl you know how I feel I really Since you be...              65  \n",
              "13539  wwI oh must go on standing You break that whic...              64  \n",
              "\n",
              "[13540 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04a57ea5-4232-4573-a57a-998d6a23c46c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>genres</th>\n",
              "      <th>lang</th>\n",
              "      <th>lyric</th>\n",
              "      <th>number_of_line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0009fFIM1eYThaPg</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>a sunny day so I got nowhere to hide Not a clo...</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00P2bHdWFkghmDqz</td>\n",
              "      <td>soul</td>\n",
              "      <td>en</td>\n",
              "      <td>Tell me a tale that always was Sing me a song ...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00b6fV3nx5z2b8Ls</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>A buh A buh You went to school to learn girl T...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>013QDoTqbexEwkHr</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>like a conversation where stops to breathe Is ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>01EKNot8qVgZpKM7</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Say the words I cannot say Say them on another...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>13535</td>\n",
              "      <td>zzT504Z94j1IAuc3</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>think what afraid of come in you know been mad...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>13536</td>\n",
              "      <td>zzgS4ZqyswamEWNj</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Oh yeah yeah Last night I took a walk in the s...</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>13537</td>\n",
              "      <td>zzx8CWdM7qkxKQpC</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Innocence it come easy in a sense it never wil...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>13538</td>\n",
              "      <td>zzz0n04uuTUA7fNh</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Girl you know how I feel I really Since you be...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>13539</td>\n",
              "      <td>zzzj3LYaZtYtbzSr</td>\n",
              "      <td>singer-songwriter</td>\n",
              "      <td>en</td>\n",
              "      <td>wwI oh must go on standing You break that whic...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04a57ea5-4232-4573-a57a-998d6a23c46c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-04a57ea5-4232-4573-a57a-998d6a23c46c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-04a57ea5-4232-4573-a57a-998d6a23c46c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "df_genre_by_lang = pd.read_csv(DIR + 'df_genre_by_lang_full.csv')\n",
        "df_genre_by_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PrRidTBHhmYp"
      },
      "outputs": [],
      "source": [
        "def load_data(df_col, y):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for line in df_col:\n",
        "        # texts are already tokenized, just split on space\n",
        "        # in a real use-case we would put more effort in preprocessing\n",
        "        texts.append(line.split(' '))\n",
        "    return pd.DataFrame({'texts': texts, 'labels': y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n5VJWiA6iJu2"
      },
      "outputs": [],
      "source": [
        "data = load_data(df_genre_by_lang[\"lyric\"], df_genre_by_lang[\"genres\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bWI4V7oXiWw6",
        "outputId": "8eb69ade-9396-4682-a9ea-182791721d37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   texts             labels\n",
              "0      [a, sunny, day, so, I, got, nowhere, to, hide,...                pop\n",
              "1      [Tell, me, a, tale, that, always, was, Sing, m...               soul\n",
              "2      [A, buh, A, buh, You, went, to, school, to, le...                pop\n",
              "3      [like, a, conversation, where, stops, to, brea...                pop\n",
              "4      [Say, the, words, I, cannot, say, Say, them, o...               rock\n",
              "...                                                  ...                ...\n",
              "13535  [think, what, afraid, of, come, in, you, know,...         indie rock\n",
              "13536  [Oh, yeah, yeah, Last, night, I, took, a, walk...                pop\n",
              "13537  [Innocence, it, come, easy, in, a, sense, it, ...         indie rock\n",
              "13538  [Girl, you, know, how, I, feel, I, really, Sin...                pop\n",
              "13539  [wwI, oh, must, go, on, standing, You, break, ...  singer-songwriter\n",
              "\n",
              "[13540 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d47c397c-b83f-48ba-80e0-19d06a814692\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[a, sunny, day, so, I, got, nowhere, to, hide,...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Tell, me, a, tale, that, always, was, Sing, m...</td>\n",
              "      <td>soul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[A, buh, A, buh, You, went, to, school, to, le...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[like, a, conversation, where, stops, to, brea...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Say, the, words, I, cannot, say, Say, them, o...</td>\n",
              "      <td>rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>[think, what, afraid, of, come, in, you, know,...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>[Oh, yeah, yeah, Last, night, I, took, a, walk...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>[Innocence, it, come, easy, in, a, sense, it, ...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>[Girl, you, know, how, I, feel, I, really, Sin...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>[wwI, oh, must, go, on, standing, You, break, ...</td>\n",
              "      <td>singer-songwriter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d47c397c-b83f-48ba-80e0-19d06a814692')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d47c397c-b83f-48ba-80e0-19d06a814692 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d47c397c-b83f-48ba-80e0-19d06a814692');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iTROinyfjc6u"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].astype('category')\n",
        "label_mapping = data['labels'].cat.categories\n",
        "data['labels'] = data['labels'].cat.codes\n",
        "X = data['texts']\n",
        "y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32Ub0-kjoOj",
        "outputId": "b5a7d7d6-a594-400d-b5a5-fce72257cadc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GnAEWk_Lza7f"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df_glove(df, feature_list, y_name):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  y = df[y_name]\n",
        "  skf.get_n_splits(df[ feature_list ], y)\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(df[ feature_list ], y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = df[ feature_list ].loc[train_index], df[ feature_list ].loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1qOv6pF0BcrV"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df(X, y):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  #y = df[y_name]\n",
        "  skf.get_n_splits(X, y)#df[ feature_list ]\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):#df[ feature_list ]\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGZPLOeBg4R",
        "outputId": "fc6078ba-c11c-44b2-b091-2e2a62e855db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [    0     1     3 ... 13537 13538 13539] TEST: [    2     4     5 ... 13526 13532 13535]\n",
            "TRAIN: [    0     2     4 ... 13535 13536 13539] TEST: [    1     3     7 ... 13530 13537 13538]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [    8    14    22 ... 13521 13531 13536]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [   10    12    15 ... 13523 13525 13534]\n",
            "TRAIN: [    1     2     3 ... 13536 13537 13538] TEST: [    0     6    11 ... 13529 13533 13539]\n"
          ]
        }
      ],
      "source": [
        "#feature_list = [\"texts\"] #this is BOW and TF-IDF\n",
        "#splits = StratifiedKFold_feature_and_df( data, feature_list, 'labels')\n",
        "splits = StratifiedKFold_feature_and_df( X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQYbmVUWPU9",
        "outputId": "aa66ce05-bb62-4a36-a17c-511cf53b0596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDMBs_gWCSLa",
        "outputId": "922ef29f-2808-4b4a-a839-e7351ecebb0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,)\n",
            "(10832,)\n",
            "(2708,)\n",
            "(2708,)\n"
          ]
        }
      ],
      "source": [
        "split0=splits[0]\n",
        "print(split0['X_train'].shape)\n",
        "print(split0['y_train'].shape)\n",
        "print(split0['X_test'].shape)\n",
        "print(split0['y_test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMmpM44is_p",
        "outputId": "1d4a3802-0460-4c6c-ab90-8d2c08fc5e5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [a, sunny, day, so, I, got, nowhere, to, hide,...\n",
              "1        [Tell, me, a, tale, that, always, was, Sing, m...\n",
              "3        [like, a, conversation, where, stops, to, brea...\n",
              "6        [Locked, up, tight, Like, I, would, never, fee...\n",
              "7        [sittin, in, the, crib, dreamin, about, leer, ...\n",
              "                               ...                        \n",
              "13534    [grandma, cookies, nigga, Shout, out, to, fron...\n",
              "13536    [Oh, yeah, yeah, Last, night, I, took, a, walk...\n",
              "13537    [Innocence, it, come, easy, in, a, sense, it, ...\n",
              "13538    [Girl, you, know, how, I, feel, I, really, Sin...\n",
              "13539    [wwI, oh, must, go, on, standing, You, break, ...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qTuHLEe8Aqg",
        "outputId": "82f6f0d8-905e-4c18-a8f4-8299af292dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "split0['y_train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONmunMa_h7T"
      },
      "source": [
        "### Use my self programmed balanced accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3KP7Dl_kdf",
        "outputId": "b39a20db-171b-4ef7-bd3a-e1a9522eb463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "339/339 [==============================] - 225s 645ms/step - loss: 0.5565 - categorical_accuracy: 0.3878 - val_loss: 1.9337 - val_categorical_accuracy: 0.3273\n",
            "Epoch 2/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5397 - categorical_accuracy: 0.3626 - val_loss: 2.0651 - val_categorical_accuracy: 0.2764\n",
            "Epoch 3/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5375 - categorical_accuracy: 0.3392 - val_loss: 2.0931 - val_categorical_accuracy: 0.2273\n",
            "Epoch 4/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5378 - categorical_accuracy: 0.3197 - val_loss: 2.0576 - val_categorical_accuracy: 0.2459\n",
            "Epoch 5/10\n",
            "339/339 [==============================] - 219s 645ms/step - loss: 0.5333 - categorical_accuracy: 0.3077 - val_loss: 2.0292 - val_categorical_accuracy: 0.2816\n",
            "Epoch 6/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5373 - categorical_accuracy: 0.2967 - val_loss: 2.1738 - val_categorical_accuracy: 0.1895\n",
            "Epoch 7/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5396 - categorical_accuracy: 0.2930 - val_loss: 2.1382 - val_categorical_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5431 - categorical_accuracy: 0.2710 - val_loss: 2.1512 - val_categorical_accuracy: 0.1965\n",
            "Epoch 9/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5450 - categorical_accuracy: 0.2729 - val_loss: 2.1854 - val_categorical_accuracy: 0.1092\n",
            "Epoch 10/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5495 - categorical_accuracy: 0.2553 - val_loss: 2.1354 - val_categorical_accuracy: 0.1594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.09744849916749872},\n",
              " {'balanced_accuracy': 0.10420636932765996},\n",
              " {'balanced_accuracy': 0.10970405736872939},\n",
              " {'balanced_accuracy': 0.10356561320774078},\n",
              " {'balanced_accuracy': 0.10792864804613309},\n",
              " {'balanced_accuracy': 0.09168989857066105},\n",
              " {'balanced_accuracy': 0.09926135499834263},\n",
              " {'balanced_accuracy': 0.10014630125778516},\n",
              " {'balanced_accuracy': 0.09807505457274496},\n",
              " {'balanced_accuracy': 0.09881853716030842}]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics])\n",
        "metrics.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzqLBSC6H175"
      },
      "source": [
        "## From here, separate X_train, X_test from KFOldSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb0KcNXhbUSN"
      },
      "source": [
        "### Preprocess my lyrics data (Official train and test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m4lLLyF-bUSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1406b6f-a1ad-4b03-f465-e9a59c2445fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 90.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip3 install transformers\n",
        "SEQ_LEN = 256#512"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUA-ps2gyvt",
        "outputId": "5c27bb15-abbd-4a05-b862-8549035d13b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        [A, buh, A, buh, You, went, to, school, to, le...\n",
              "4        [Say, the, words, I, cannot, say, Say, them, o...\n",
              "5        [I, was, alone, I, was, made, of, stone, You, ...\n",
              "9        [Again, the, burden, of, losing, rests, upon, ...\n",
              "20       [only, been, three, weeks, And, a, bag, of, sp...\n",
              "                               ...                        \n",
              "13517    [Like, the, legend, of, the, Phoenix, All, end...\n",
              "13522    [Mr, Telephone, man, something, wrong, with, m...\n",
              "13526    [can, you, imagine, what, it, would, be, like,...\n",
              "13532    [Love, of, my, life, hurt, me, broken, my, hea...\n",
              "13535    [think, what, afraid, of, come, in, you, know,...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_lyrics(X_series):\n",
        "  for i, token_list in X_series.items():\n",
        "    if type(token_list) is list:\n",
        "      X_series.loc[i] = ' '.join(token_list)\n",
        "  return X_series"
      ],
      "metadata": {
        "id": "PqFwOGTIbhiZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzTIRCW1cUwV",
        "outputId": "03c719aa-be61-4918-ee3d-f1428e1b18a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        A buh A buh You went to school to learn girl T...\n",
              "4        Say the words I cannot say Say them on another...\n",
              "5        I was alone I was made of stone You took me ho...\n",
              "9        Again the burden of losing rests upon my shoul...\n",
              "20       only been three weeks And a bag of speed from ...\n",
              "                               ...                        \n",
              "13517    Like the legend of the Phoenix All ends with b...\n",
              "13522    Mr Telephone man something wrong with my line ...\n",
              "13526    can you imagine what it would be like we never...\n",
              "13532    Love of my life hurt me broken my heart and no...\n",
              "13535    think what afraid of come in you know been mad...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_train'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxixg4yAcAfe",
        "outputId": "ba124b06-7c71-4c23-a2fd-753d8cce7c90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        a sunny day so I got nowhere to hide Not a clo...\n",
              "1        Tell me a tale that always was Sing me a song ...\n",
              "3        like a conversation where stops to breathe Is ...\n",
              "6        Locked up tight Like I would never feel again ...\n",
              "7        sittin in the crib dreamin about leer jets and...\n",
              "                               ...                        \n",
              "13534    grandma cookies nigga Shout out to fronto leaf...\n",
              "13536    Oh yeah yeah Last night I took a walk in the s...\n",
              "13537    Innocence it come easy in a sense it never wil...\n",
              "13538    Girl you know how I feel I really Since you be...\n",
              "13539    wwI oh must go on standing You break that whic...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['y_train'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9UxO1GAcfoI",
        "outputId": "995da507-5df8-4a33-d2ca-03f0d307bb9d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use ALBERT\n",
        "Be careful, you need sentencepiece library:https://stackoverflow.com/questions/65854722/huggingface-albert-tokenizer-nonetype-error-with-colab"
      ],
      "metadata": {
        "id": "9zWdtsKTSIjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClJ2DWKVs0Q",
        "outputId": "fe865899-ba0f-42e4-db74-4d754c6e250a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4959f69a9ef54f03814b9a97ffbfce93",
            "c5b6dd20508d4d18a6fffdf813166957",
            "7fa4898e5b184684a429c5c7ff430c29",
            "9005cb8f77f64ebea7d9114decc9536b",
            "a427b331158c4f1eac7d0df94a66063b",
            "d0f49d0f4745475eb79a00b800391ac6",
            "069b4baf890d46bdb5f2d17764ef20e1",
            "64e81535265d44db9d275770e3bf8d37",
            "c1142ae2ce9543e7929408dca1367677",
            "ce14a81fd4e8402183c340b4973746e8",
            "b2c534b37f2e403486a0fdcffe0e0629",
            "f62572e42db14e5e9af9c2758c54454d",
            "a515fca234754cbb98ccf65a3781e47e",
            "8be186e581f047fea6ce883da1d4c0b1",
            "42f7832394364b5fb9b8c991fe5aa539",
            "ff602015a67b4d518aa80d463f7e8f92",
            "617b3f1beab849938c57eb129b55deb9",
            "791d6d82fe30472daafa321f4eb0c290",
            "7de52522216948b29f9f1d79c0315877",
            "a82895b5f5c54a0ea2c301f4eedaf27c",
            "37d272255b0445038196f2b4d0ec9e5c",
            "56f8aae43cfd401a9dee6a968cbb3401"
          ]
        },
        "id": "SV33Uvd7VYXJ",
        "outputId": "a6f04964-2d80-4c03-f9f4-b8cc79cf6867"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/742k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4959f69a9ef54f03814b9a97ffbfce93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f62572e42db14e5e9af9c2758c54454d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "print(Xids_train.shape, Xids_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt_zTUp0SKST",
        "outputId": "0df64110-2dfd-4385-996c-3fefc36a1fb5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4YypbKsbUSQ"
      },
      "source": [
        "Create y labels in transformer format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FESnc0UIbUSQ"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VFYtD7rybUSQ"
      },
      "outputs": [],
      "source": [
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-FgpLfmjtZW",
        "outputId": "a4d1e71a-a232-49d9-cc21-14740a6d4e7b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "J7xk5236bUSR"
      },
      "outputs": [],
      "source": [
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids': input_ids, 'attention_mask':masks}, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nXygicJBbUSR"
      },
      "outputs": [],
      "source": [
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2374b5-d0a7-4eb5-8ab1-98e45d037fa5",
        "id": "jqWHoZJebUSR"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "677"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "DS_LEN = len(list(dataset_train))\n",
        "DS_LEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVuShbZzbUSS"
      },
      "source": [
        "339 because 10800/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23717c3e-7185-4c3d-ba00-fd6af8d69d51",
        "id": "cg9c-e5jbUSS"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "SPLIT = 0.9\n",
        "round(DS_LEN*SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(split0['X_train'])-int(len(split0['X_train'])*0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-e9iZTaasAJ",
        "outputId": "f232956c-e6c0-496b-d3f8-529ebe029264"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1084"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b1VgA6bIbUSS"
      },
      "outputs": [],
      "source": [
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))#remainer is for val."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "id": "1GzPKw9sXgOB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "77foZE_rZc9E"
      },
      "outputs": [],
      "source": [
        "def map_func_only_X(val_dictionary, labels):\n",
        "  return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-n1WkoHFZc9H"
      },
      "outputs": [],
      "source": [
        "def map_func_only_y(val_dictionary, labels):\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=1084"
      ],
      "metadata": {
        "id": "Q-VGMZy5bRfN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48348314-a8e0-497b-8315-771965dd3484",
        "id": "wZDVrP0QYC_n"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "counter = Counter(split0['y_train'])\n",
        "SUM=0\n",
        "for item in list(counter.values()) :\n",
        "  SUM+=item\n",
        "#SUM = sum(counter.values())\n",
        "SUM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tutorial\n",
        "#weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "#weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "counter = Counter(split0['y_train'])\n",
        "my_weight2 = {}\n",
        "print(counter)\n",
        "\n",
        "for genre in counter:\n",
        "  #print(genre, counter[genre])\n",
        "  my_weight2[genre] = (1/counter[genre]) * (SUM/10)\n",
        "my_weight2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbDe9DVFAvjP",
        "outputId": "ab5cf5f9-2cb2-4a2a-b618-1d2e76836157"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({4: 4143, 7: 1159, 9: 1030, 3: 865, 6: 783, 0: 763, 1: 690, 8: 556, 2: 537, 5: 306})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 0.2614530533429882,\n",
              " 9: 1.051650485436893,\n",
              " 6: 1.383397190293742,\n",
              " 2: 2.0171322160148977,\n",
              " 0: 1.4196592398427261,\n",
              " 7: 0.9345987920621226,\n",
              " 1: 1.569855072463768,\n",
              " 5: 3.539869281045752,\n",
              " 8: 1.948201438848921,\n",
              " 3: 1.2522543352601156}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = split0[\"y_test\"].shape[0]\n",
        "TEST_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js6dH6oJAE25",
        "outputId": "4e2df928-a581-4bf4-ec18-555dc016b89d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2708"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oylD4vpEYC_m"
      },
      "source": [
        "### Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6c35bf-4117-450c-ee04-36aafb9f83cc",
        "id": "FSUwCq41YC_n"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4143"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "MAX = max(counter.values())\n",
        "MAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f05a11-a401-495b-ffe4-08e5d23df979",
        "id": "W43besBMYC_o"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5.4298820445609435,\n",
              " 1: 6.004347826086956,\n",
              " 2: 7.715083798882682,\n",
              " 3: 4.789595375722543,\n",
              " 4: 1.0,\n",
              " 5: 13.53921568627451,\n",
              " 6: 5.291187739463601,\n",
              " 7: 3.5746333045729077,\n",
              " 8: 7.451438848920863,\n",
              " 9: 4.022330097087378}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "my_weight={}\n",
        "\n",
        "for genre in range(10):\n",
        "  my_weight[genre]=MAX/counter[genre]\n",
        "#sum(weight)\n",
        "my_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850,
          "referenced_widgets": [
            "662d0f403d1e4dfeb6fc29be94f50198",
            "8f0af31782e5435581e80666c77478bd",
            "53abe4f95cf345869a3b6f44f96b1520",
            "6556acea07544f8c8f414265f2d87511",
            "69713da665c64ba8b168483309af40e8",
            "9d139056dee4493abaa1e2757840091b",
            "0803723664024e8b8e036b3886110483",
            "4c4aaf7d3d784d08973922bb7f50bf07",
            "b7d2fb18cb0748a69be07610ec5be7d3",
            "ecc37a448c8c48c1a5910f19a3c06730",
            "1acbc29d6f914422883ae875cad5fef5"
          ]
        },
        "outputId": "895c8af8-9ed8-4c04-dbaf-4d864ea941b9",
        "id": "3F3ZnDSzZc8_"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "662d0f403d1e4dfeb6fc29be94f50198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,416,234\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 108,311,808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModel\n",
        "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name='attention_mask')\n",
        "\n",
        "embeddings = bert(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.1)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model.layers[2].trainable = False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeprUFLfZc9B"
      },
      "source": [
        "BERT is huge, so here we don't fine tune BERT. Simply use pre-trained base BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azlG0LBWZc9C"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model.compile(optimizer=optimizer, loss= loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lphE0vKbZc9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c926cad6-0580-49eb-e154-c7e7e3fd7600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339 305 34 85\n"
          ]
        }
      ],
      "source": [
        "print(DS_LEN, len(train), len(val), len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBQRA55rZc9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1958d5-7c26-4922-addc-4ddd05bd8f35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1088"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "VAL_SIZE = len(val)*32\n",
        "VAL_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8RRutv3Zc9E"
      },
      "outputs": [],
      "source": [
        "#print(len(val.take(len(val))))\n",
        "for item, label_batch in val.take(1):#len(val)\n",
        "  print(item['input_ids'])\n",
        "  #one_batch= item[0]['input_ids']\n",
        "  #for xids in one_batch:\n",
        "  #  print(xids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f984a0cb-27f7-416e-8978-530eb9c0ed54",
        "id": "Pv5OpZRWZc9E"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ],
      "source": [
        "val_X = val.map(map_func_only_X)\n",
        "print(len(val_X))\n",
        "#for i in val_X.take(1):\n",
        "  #print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcQkXXWUZc9H"
      },
      "outputs": [],
      "source": [
        "val_y = val.map(map_func_only_y)\n",
        "print(len(val_y))\n",
        "y_category=np.zeros((VAL_SIZE, ))\n",
        "counter=0\n",
        "for label_tensor in val_y.take(1):\n",
        "  #print(label_tensor)\n",
        "  y_val = np.argmax(label_tensor, axis=1)\n",
        "  for label in y_val:\n",
        "    print(label) \n",
        "    y_category[counter]=label\n",
        "    counter+=1\n",
        "print('counter:',counter)\n",
        "print(y_category)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=1072\n",
        "VAL_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlboX0e9aOOU",
        "outputId": "dd0ddbd7-a925-45a8-971e-d176463d010b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1072"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=len(split0['X_train'])-int(len(split0['X_train'])*0.9)\n",
        "VAL_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TkIIrbvbGlZ",
        "outputId": "01b11abc-52ed-47d3-da2c-8b1cf82b91c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1084"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_y = val2.map(map_func_only_y)\n",
        "print(len(val_y))\n",
        "y_category=np.zeros((VAL_SIZE, ))\n",
        "counter=0\n",
        "for label_tensor in val_y.take(len(val2)):\n",
        "  #print(label_tensor)\n",
        "  y_val = np.argmax(label_tensor, axis=1)\n",
        "  for label in y_val:\n",
        "    print(label) \n",
        "    y_category[counter]=label\n",
        "    counter+=1\n",
        "print('counter:',counter)\n",
        "print(y_category)"
      ],
      "metadata": {
        "id": "ZbaDLzG0Z9rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch0PrqHiZc9I"
      },
      "source": [
        "Ref1: how to calculate genre as int instead of one hot vector from list of one hot vectors.\n",
        "https://www.sharpsightlabs.com/blog/numpy-argmax/\n",
        "\n",
        "Ref2: How to use self-programmed metrics: https://stackoverflow.com/questions/37657260/how-to-implement-custom-metric-in-keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MFJlAaBZc9I"
      },
      "outputs": [],
      "source": [
        "VAL_SIZE=1072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuQBamEdZc9I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self._data = []\n",
        "        self.validation_data = val2\n",
        "\n",
        "    def map_func_only_X(val_dictionary, labels):\n",
        "      return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}\n",
        "    def map_func_only_y(val_dictionary, labels):\n",
        "      return labels\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "      #Xid_list= np.zeros((VAL_SIZE, SEQ_LEN))\n",
        "      #y_onehot_list= np.zeros((VAL_SIZE, 10))\n",
        "      #counter=0\n",
        "      #for item in dataset.take(len(self.validation_data)):\n",
        "      #for item in val.take(len(val)):\n",
        "      \"\"\"\n",
        "      for item, batch_label in self.validation_data.take(len(val)):\n",
        "        for label in batch_label:\n",
        "          y_onehot_list[counter,:] = label\n",
        "          counter+=1\n",
        "        one_batch_xid = item['input_ids']\n",
        "        for xids in one_batch_xid:\n",
        "          Xid_list[counter, :] = xids\n",
        "        \n",
        "        #X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
        "      \"\"\"\n",
        "      val_y = self.validation_data.map(map_func_only_y)\n",
        "      y_category=np.zeros((VAL_SIZE, ))\n",
        "      counter=0\n",
        "      for label_tensor in val_y.take(len(val_y)):\n",
        "        y_val = np.argmax(label_tensor, axis=1)\n",
        "        for label in y_val:\n",
        "          y_category[counter]=label\n",
        "          counter+=1\n",
        "      X_val, y_val =self.validation_data.map(map_func_only_X), y_category\n",
        "      y_predict = np.asarray(model2.predict(X_val))\n",
        "\n",
        "      #y_val = np.argmax(y_val, axis=1)#I have already done converting to category\n",
        "      y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "      self._data.append({\n",
        "          'balanced_accuracy': balanced_accuracy_score(y_val, y_predict),\n",
        "          #'val_rocauc': roc_auc_score(y_val, y_predict),\n",
        "      })\n",
        "      return\n",
        "\n",
        "    def get_data(self):\n",
        "        return self._data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer learning: try early stopping with SEQ_LEN=512"
      ],
      "metadata": {
        "id": "wr-sII815ZQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "\n",
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics, early_stopping])\n",
        "metrics.get_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3xJUqUP5bhP",
        "outputId": "2ea8e267-26ee-467b-fd5f-05b16db30f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "305/305 [==============================] - 165s 541ms/step - loss: 7.4384 - categorical_accuracy: 0.2784 - val_loss: 2.1002 - val_categorical_accuracy: 0.2118\n",
            "Epoch 2/10\n",
            "305/305 [==============================] - 165s 541ms/step - loss: 7.0577 - categorical_accuracy: 0.3053 - val_loss: 2.0583 - val_categorical_accuracy: 0.2435\n",
            "Epoch 3/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.7958 - categorical_accuracy: 0.3207 - val_loss: 1.9879 - val_categorical_accuracy: 0.2677\n",
            "Epoch 4/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.5908 - categorical_accuracy: 0.3376 - val_loss: 2.0138 - val_categorical_accuracy: 0.2388\n",
            "Epoch 5/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.4173 - categorical_accuracy: 0.3493 - val_loss: 2.0363 - val_categorical_accuracy: 0.2472\n",
            "Epoch 6/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.2501 - categorical_accuracy: 0.3629 - val_loss: 2.0147 - val_categorical_accuracy: 0.2509\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.10064757124688836},\n",
              " {'balanced_accuracy': 0.1187677795399048},\n",
              " {'balanced_accuracy': 0.09990412917019217},\n",
              " {'balanced_accuracy': 0.08602748843296298},\n",
              " {'balanced_accuracy': 0.12293896335258817},\n",
              " {'balanced_accuracy': 0.08466265273217208}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "test_y = test.map(map_func_only_y)\n",
        "y_category=np.zeros((TEST_SIZE, ))\n",
        "counter=0\n",
        "for label_tensor in test_y.take(len(test_y)):\n",
        "  y_test = np.argmax(label_tensor, axis=1)\n",
        "  for label in y_test:\n",
        "    y_category[counter]=label\n",
        "    counter+=1\n",
        "\n",
        "X_test, y_test = test.map(map_func_only_X), y_category\n",
        "y_predict_test = np.asarray(model.predict(X_test))\n",
        "y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "print(classification_report(y_test, y_predict_test) )\n",
        "print(balanced_accuracy_score(y_test, y_predict_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu5dCLm6noXw",
        "outputId": "a7b5a378-91e9-475d-b302-3c51cd515635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.42      0.21       190\n",
            "         1.0       0.16      0.28      0.20       173\n",
            "         2.0       0.10      0.14      0.12       135\n",
            "         3.0       0.13      0.17      0.15       216\n",
            "         4.0       0.74      0.19      0.31      1036\n",
            "         5.0       0.12      0.38      0.18        76\n",
            "         6.0       0.77      0.77      0.77       195\n",
            "         7.0       0.11      0.08      0.10       290\n",
            "         8.0       0.09      0.09      0.09       139\n",
            "         9.0       0.24      0.28      0.26       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.26      0.28      0.24      2708\n",
            "weighted avg       0.42      0.25      0.26      2708\n",
            "\n",
            "0.2825509565558356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning -> Fine tunine: unfreeze middle layers and train with smaller learning rate. using ALBERT base"
      ],
      "metadata": {
        "id": "L23dKb22nfQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN2=256"
      ],
      "metadata": {
        "id": "0NyVM7_KZjox"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "albert_base = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "\n",
        "drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "for drop_out_rate in drop_out_rates:\n",
        "  #step1\n",
        "  input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "  mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "  embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "  X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "  X = tf.keras.layers.BatchNormalization()(X)\n",
        "  X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "  X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "  X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "  y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "  model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "  model2.layers[2].trainable = False\n",
        "  #model2.summary()\n",
        "\n",
        "  #step2\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "  metrics = []\n",
        "  metrics.append(\n",
        "      tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "  model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "  #model2.summary() #Check trainable params increased.\n",
        "\n",
        "  #step3: transfer learning\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "  history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "  #step4: predict\n",
        "  balanced_acc=get_balanced_accuracy(model2)\n",
        "  balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "  #step5: fine tune\n",
        "  model2.layers[2].trainable = True\n",
        "\n",
        "  # It's important to recompile your model after you make any changes\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "  metrics = []\n",
        "  metrics.append(\n",
        "      tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "  model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "  history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "  balanced_acc=get_balanced_accuracy(model2)\n",
        "  balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "  del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxbPCm_hU9iZ",
        "outputId": "6704ea91-703f-4908-b448-f70036247756"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 247s 369ms/step - loss: 2.0898 - categorical_accuracy: 0.2449 - val_loss: 1.9160 - val_categorical_accuracy: 0.2895\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 220s 361ms/step - loss: 1.6881 - categorical_accuracy: 0.3587 - val_loss: 1.8891 - val_categorical_accuracy: 0.3015\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.4174 - categorical_accuracy: 0.4352 - val_loss: 1.8973 - val_categorical_accuracy: 0.3153\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.1821 - categorical_accuracy: 0.4992 - val_loss: 2.0300 - val_categorical_accuracy: 0.2923\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 0.9610 - categorical_accuracy: 0.5565 - val_loss: 2.1120 - val_categorical_accuracy: 0.2996\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 0.8037 - categorical_accuracy: 0.6061 - val_loss: 2.1925 - val_categorical_accuracy: 0.3189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.15      0.14       190\n",
            "         1.0       0.15      0.19      0.17       173\n",
            "         2.0       0.09      0.13      0.11       135\n",
            "         3.0       0.19      0.15      0.17       216\n",
            "         4.0       0.66      0.36      0.46      1036\n",
            "         5.0       0.20      0.25      0.22        76\n",
            "         6.0       0.68      0.72      0.70       195\n",
            "         7.0       0.16      0.19      0.17       290\n",
            "         8.0       0.10      0.22      0.14       139\n",
            "         9.0       0.23      0.35      0.28       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.26      0.27      0.26      2708\n",
            "weighted avg       0.39      0.30      0.33      2708\n",
            "\n",
            "0.2714461328340759\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 570s 892ms/step - loss: 2.0808 - categorical_accuracy: 0.3358 - val_loss: 2.3407 - val_categorical_accuracy: 0.2739\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 539s 884ms/step - loss: 2.2728 - categorical_accuracy: 0.2945 - val_loss: 2.5517 - val_categorical_accuracy: 0.3079\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 539s 885ms/step - loss: 2.0363 - categorical_accuracy: 0.3161 - val_loss: 2.5536 - val_categorical_accuracy: 0.2390\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 538s 884ms/step - loss: 1.7753 - categorical_accuracy: 0.3454 - val_loss: 2.4465 - val_categorical_accuracy: 0.2417\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 538s 884ms/step - loss: 1.5539 - categorical_accuracy: 0.3792 - val_loss: 2.3367 - val_categorical_accuracy: 0.2665\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.13      0.14       190\n",
            "         1.0       0.15      0.38      0.21       173\n",
            "         2.0       0.07      0.07      0.07       135\n",
            "         3.0       0.19      0.13      0.15       216\n",
            "         4.0       0.66      0.24      0.35      1036\n",
            "         5.0       0.15      0.30      0.20        76\n",
            "         6.0       0.64      0.77      0.70       195\n",
            "         7.0       0.14      0.12      0.13       290\n",
            "         8.0       0.09      0.18      0.12       139\n",
            "         9.0       0.20      0.40      0.26       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.24      0.27      0.23      2708\n",
            "weighted avg       0.38      0.26      0.28      2708\n",
            "\n",
            "0.27205025845354136\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 369ms/step - loss: 2.0334 - categorical_accuracy: 0.2658 - val_loss: 1.9282 - val_categorical_accuracy: 0.2969\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 220s 361ms/step - loss: 1.6390 - categorical_accuracy: 0.3753 - val_loss: 1.8546 - val_categorical_accuracy: 0.3346\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 220s 361ms/step - loss: 1.4180 - categorical_accuracy: 0.4187 - val_loss: 1.9456 - val_categorical_accuracy: 0.3051\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.2274 - categorical_accuracy: 0.4794 - val_loss: 1.9445 - val_categorical_accuracy: 0.3263\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.0814 - categorical_accuracy: 0.5196 - val_loss: 2.0249 - val_categorical_accuracy: 0.3300\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.27      0.23       190\n",
            "         1.0       0.15      0.23      0.18       173\n",
            "         2.0       0.18      0.12      0.14       135\n",
            "         3.0       0.19      0.25      0.21       216\n",
            "         4.0       0.66      0.36      0.47      1036\n",
            "         5.0       0.21      0.14      0.17        76\n",
            "         6.0       0.70      0.77      0.73       195\n",
            "         7.0       0.15      0.13      0.14       290\n",
            "         8.0       0.09      0.17      0.12       139\n",
            "         9.0       0.23      0.40      0.29       258\n",
            "\n",
            "    accuracy                           0.32      2708\n",
            "   macro avg       0.27      0.28      0.27      2708\n",
            "weighted avg       0.40      0.32      0.34      2708\n",
            "\n",
            "0.2846293000154242\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 891ms/step - loss: 2.3535 - categorical_accuracy: 0.2771 - val_loss: 4.3616 - val_categorical_accuracy: 0.0772\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.9284 - categorical_accuracy: 0.3013 - val_loss: 3.9277 - val_categorical_accuracy: 0.0993\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.8030 - categorical_accuracy: 0.3387 - val_loss: 3.6848 - val_categorical_accuracy: 0.1756\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 883ms/step - loss: 1.7356 - categorical_accuracy: 0.3471 - val_loss: 2.4950 - val_categorical_accuracy: 0.2886\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 1.9671 - categorical_accuracy: 0.3207 - val_loss: 5.9806 - val_categorical_accuracy: 0.0551\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 535s 879ms/step - loss: 2.1460 - categorical_accuracy: 0.2602 - val_loss: 7.0500 - val_categorical_accuracy: 0.0561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.01      0.01      0.01       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.03      0.64      0.05        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       0.11      0.25      0.15       290\n",
            "         8.0       0.03      0.02      0.02       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.05      2708\n",
            "   macro avg       0.02      0.09      0.02      2708\n",
            "weighted avg       0.01      0.05      0.02      2708\n",
            "\n",
            "0.09203757848079876\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 368ms/step - loss: 2.1277 - categorical_accuracy: 0.2306 - val_loss: 2.0056 - val_categorical_accuracy: 0.2500\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 2.0269 - categorical_accuracy: 0.2410 - val_loss: 1.9747 - val_categorical_accuracy: 0.2702\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 2.0083 - categorical_accuracy: 0.2414 - val_loss: 1.9780 - val_categorical_accuracy: 0.2684\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 2.0033 - categorical_accuracy: 0.2453 - val_loss: 1.9714 - val_categorical_accuracy: 0.2840\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.9938 - categorical_accuracy: 0.2513 - val_loss: 1.9551 - val_categorical_accuracy: 0.3373\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.9878 - categorical_accuracy: 0.2597 - val_loss: 1.9587 - val_categorical_accuracy: 0.3281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.07      0.09       190\n",
            "         1.0       0.10      0.12      0.11       173\n",
            "         2.0       0.33      0.01      0.01       135\n",
            "         3.0       0.13      0.20      0.16       216\n",
            "         4.0       0.58      0.58      0.58      1036\n",
            "         5.0       0.07      0.34      0.11        76\n",
            "         6.0       0.54      0.86      0.66       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.07      0.10      0.08       139\n",
            "         9.0       0.25      0.12      0.17       258\n",
            "\n",
            "    accuracy                           0.34      2708\n",
            "   macro avg       0.22      0.24      0.20      2708\n",
            "weighted avg       0.34      0.34      0.32      2708\n",
            "\n",
            "0.24044978540726597\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 568s 892ms/step - loss: 2.0029 - categorical_accuracy: 0.3153 - val_loss: 5.8892 - val_categorical_accuracy: 0.1452\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 880ms/step - loss: 1.8961 - categorical_accuracy: 0.3041 - val_loss: 2.9597 - val_categorical_accuracy: 0.2472\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.8184 - categorical_accuracy: 0.3083 - val_loss: 2.1188 - val_categorical_accuracy: 0.2629\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.7148 - categorical_accuracy: 0.2889 - val_loss: 4.4864 - val_categorical_accuracy: 0.1011\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.6261 - categorical_accuracy: 0.2948 - val_loss: 2.2003 - val_categorical_accuracy: 0.2077\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.5460 - categorical_accuracy: 0.2943 - val_loss: 1.9049 - val_categorical_accuracy: 0.2546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.43      0.20       190\n",
            "         1.0       0.15      0.08      0.10       173\n",
            "         2.0       0.06      0.13      0.08       135\n",
            "         3.0       0.16      0.19      0.18       216\n",
            "         4.0       0.48      0.15      0.22      1036\n",
            "         5.0       0.23      0.24      0.23        76\n",
            "         6.0       0.84      0.72      0.78       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.19      0.65      0.29       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.22      0.26      0.21      2708\n",
            "weighted avg       0.30      0.23      0.21      2708\n",
            "\n",
            "0.2580569761133787\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 367ms/step - loss: 1.6436 - categorical_accuracy: 0.3229 - val_loss: 1.9396 - val_categorical_accuracy: 0.2785\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.4531 - categorical_accuracy: 0.3365 - val_loss: 2.0896 - val_categorical_accuracy: 0.2472\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.4436 - categorical_accuracy: 0.3503 - val_loss: 2.1367 - val_categorical_accuracy: 0.2721\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.4119 - categorical_accuracy: 0.3599 - val_loss: 2.0536 - val_categorical_accuracy: 0.2619\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.15      0.18       190\n",
            "         1.0       0.16      0.18      0.17       173\n",
            "         2.0       0.06      0.22      0.09       135\n",
            "         3.0       0.16      0.25      0.20       216\n",
            "         4.0       0.55      0.17      0.26      1036\n",
            "         5.0       0.42      0.07      0.11        76\n",
            "         6.0       0.81      0.74      0.77       195\n",
            "         7.0       0.21      0.02      0.04       290\n",
            "         8.0       0.10      0.25      0.15       139\n",
            "         9.0       0.19      0.51      0.28       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.29      0.26      0.23      2708\n",
            "weighted avg       0.37      0.24      0.24      2708\n",
            "\n",
            "0.2560964586279497\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 891ms/step - loss: 1.4192 - categorical_accuracy: 0.3681 - val_loss: 2.9397 - val_categorical_accuracy: 0.2822\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.3136 - categorical_accuracy: 0.3799 - val_loss: 4.1014 - val_categorical_accuracy: 0.1756\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.2501 - categorical_accuracy: 0.3862 - val_loss: 3.1378 - val_categorical_accuracy: 0.1866\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.1917 - categorical_accuracy: 0.4078 - val_loss: 3.2733 - val_categorical_accuracy: 0.2197\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.73      0.18       190\n",
            "         1.0       0.17      0.06      0.09       173\n",
            "         2.0       0.05      0.13      0.07       135\n",
            "         3.0       0.16      0.07      0.10       216\n",
            "         4.0       0.61      0.12      0.21      1036\n",
            "         5.0       0.45      0.07      0.11        76\n",
            "         6.0       0.80      0.74      0.77       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.05      0.01      0.02       139\n",
            "         9.0       0.21      0.33      0.25       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.26      0.23      0.18      2708\n",
            "weighted avg       0.36      0.20      0.19      2708\n",
            "\n",
            "0.227055276787063\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 367ms/step - loss: 1.4062 - categorical_accuracy: 0.4185 - val_loss: 2.2085 - val_categorical_accuracy: 0.2886\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.1824 - categorical_accuracy: 0.4264 - val_loss: 2.3885 - val_categorical_accuracy: 0.2803\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.1450 - categorical_accuracy: 0.4421 - val_loss: 2.4581 - val_categorical_accuracy: 0.2858\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.1096 - categorical_accuracy: 0.4474 - val_loss: 2.4476 - val_categorical_accuracy: 0.2840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.07      0.11       190\n",
            "         1.0       0.15      0.07      0.10       173\n",
            "         2.0       0.04      0.14      0.06       135\n",
            "         3.0       0.20      0.16      0.18       216\n",
            "         4.0       0.61      0.21      0.31      1036\n",
            "         5.0       0.71      0.07      0.12        76\n",
            "         6.0       0.80      0.77      0.79       195\n",
            "         7.0       0.14      0.19      0.16       290\n",
            "         8.0       0.11      0.32      0.16       139\n",
            "         9.0       0.21      0.41      0.27       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.32      0.24      0.23      2708\n",
            "weighted avg       0.39      0.24      0.26      2708\n",
            "\n",
            "0.24175213805787257\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 567s 889ms/step - loss: 1.3344 - categorical_accuracy: 0.4152 - val_loss: 2.0446 - val_categorical_accuracy: 0.2748\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.2897 - categorical_accuracy: 0.4080 - val_loss: 2.5091 - val_categorical_accuracy: 0.2592\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 1.1043 - categorical_accuracy: 0.4618 - val_loss: 1.9240 - val_categorical_accuracy: 0.2702\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 1.0043 - categorical_accuracy: 0.4783 - val_loss: 2.7361 - val_categorical_accuracy: 0.2537\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.15      0.18       190\n",
            "         1.0       0.17      0.12      0.14       173\n",
            "         2.0       0.05      0.18      0.08       135\n",
            "         3.0       0.22      0.14      0.17       216\n",
            "         4.0       0.52      0.15      0.24      1036\n",
            "         5.0       0.40      0.11      0.17        76\n",
            "         6.0       0.83      0.70      0.76       195\n",
            "         7.0       0.13      0.13      0.13       290\n",
            "         8.0       0.10      0.20      0.14       139\n",
            "         9.0       0.20      0.57      0.29       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.28      0.25      0.23      2708\n",
            "weighted avg       0.35      0.23      0.24      2708\n",
            "\n",
            "0.24536153069686137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_transfer_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673nstNCNBBZ",
        "outputId": "007dac37-8233-4786-b43b-cb34e8eb93c0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2714461328340759,\n",
              " 0.2846293000154242,\n",
              " 0.24044978540726597,\n",
              " 0.2560964586279497,\n",
              " 0.24175213805787257]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdNc02xLM7j9",
        "outputId": "fba51e39-b5d8-4b1e-d9a3-3f2ff6793744"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27205025845354136,\n",
              " 0.09203757848079876,\n",
              " 0.2580569761133787,\n",
              " 0.227055276787063,\n",
              " 0.24536153069686137]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters = []\n",
        "drop_out_rates=[0.1,0.2,0.3,0.4,0.5]\n",
        "for dropout in drop_out_rates:\n",
        "  seen_parameters.append((1e-3, 1e-5, dropout))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fho5_oVm5yhj",
        "outputId": "15580a76-2860-4925-ee81-743c7d6cdfd1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.1]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "id": "HKOGrCtH5tl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.2]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUTlIsmH7QDl",
        "outputId": "cb22a7b8-2b53-408f-edf7-51a75945fbd6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 366ms/step - loss: 0.9767 - categorical_accuracy: 0.5497 - val_loss: 3.1171 - val_categorical_accuracy: 0.2730\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.8618 - categorical_accuracy: 0.5754 - val_loss: 2.8146 - val_categorical_accuracy: 0.2941\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.8139 - categorical_accuracy: 0.5956 - val_loss: 2.7685 - val_categorical_accuracy: 0.3079\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.8014 - categorical_accuracy: 0.5962 - val_loss: 2.9234 - val_categorical_accuracy: 0.2950\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.7832 - categorical_accuracy: 0.5935 - val_loss: 2.9021 - val_categorical_accuracy: 0.3033\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.7746 - categorical_accuracy: 0.5939 - val_loss: 3.0508 - val_categorical_accuracy: 0.2886\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.11      0.15       190\n",
            "         1.0       0.14      0.06      0.09       173\n",
            "         2.0       0.06      0.13      0.09       135\n",
            "         3.0       0.21      0.19      0.20       216\n",
            "         4.0       0.56      0.30      0.39      1036\n",
            "         5.0       0.40      0.11      0.17        76\n",
            "         6.0       0.84      0.69      0.76       195\n",
            "         7.0       0.13      0.26      0.18       290\n",
            "         8.0       0.09      0.23      0.13       139\n",
            "         9.0       0.21      0.34      0.26       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.29      0.24      0.24      2708\n",
            "weighted avg       0.37      0.27      0.29      2708\n",
            "\n",
            "0.24114452614265702\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 570s 890ms/step - loss: 0.7486 - categorical_accuracy: 0.6236 - val_loss: 3.1019 - val_categorical_accuracy: 0.2996\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.6095 - categorical_accuracy: 0.6602 - val_loss: 3.2936 - val_categorical_accuracy: 0.2932\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.5196 - categorical_accuracy: 0.6862 - val_loss: 3.3856 - val_categorical_accuracy: 0.3033\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.4613 - categorical_accuracy: 0.7094 - val_loss: 3.5947 - val_categorical_accuracy: 0.2996\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.4068 - categorical_accuracy: 0.7328 - val_loss: 3.7525 - val_categorical_accuracy: 0.3051\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.3547 - categorical_accuracy: 0.7519 - val_loss: 3.9182 - val_categorical_accuracy: 0.3024\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.11      0.15       190\n",
            "         1.0       0.17      0.09      0.12       173\n",
            "         2.0       0.06      0.16      0.09       135\n",
            "         3.0       0.20      0.27      0.23       216\n",
            "         4.0       0.56      0.29      0.38      1036\n",
            "         5.0       0.50      0.09      0.16        76\n",
            "         6.0       0.82      0.74      0.78       195\n",
            "         7.0       0.15      0.23      0.18       290\n",
            "         8.0       0.11      0.23      0.15       139\n",
            "         9.0       0.22      0.38      0.28       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.30      0.26      0.25      2708\n",
            "weighted avg       0.38      0.28      0.30      2708\n",
            "\n",
            "0.2591786542521592\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 366ms/step - loss: 0.5864 - categorical_accuracy: 0.7268 - val_loss: 3.1348 - val_categorical_accuracy: 0.3428\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.3287 - categorical_accuracy: 0.7911 - val_loss: 3.3260 - val_categorical_accuracy: 0.3318\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.3042 - categorical_accuracy: 0.7972 - val_loss: 3.4778 - val_categorical_accuracy: 0.3401\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2960 - categorical_accuracy: 0.7960 - val_loss: 3.5928 - val_categorical_accuracy: 0.3346\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.10      0.14       190\n",
            "         1.0       0.18      0.09      0.12       173\n",
            "         2.0       0.08      0.12      0.10       135\n",
            "         3.0       0.19      0.13      0.16       216\n",
            "         4.0       0.55      0.44      0.49      1036\n",
            "         5.0       0.54      0.09      0.16        76\n",
            "         6.0       0.81      0.74      0.78       195\n",
            "         7.0       0.13      0.22      0.17       290\n",
            "         8.0       0.11      0.30      0.16       139\n",
            "         9.0       0.22      0.26      0.24       258\n",
            "\n",
            "    accuracy                           0.32      2708\n",
            "   macro avg       0.30      0.25      0.25      2708\n",
            "weighted avg       0.37      0.32      0.33      2708\n",
            "\n",
            "0.2493581581035141\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 568s 889ms/step - loss: 0.6903 - categorical_accuracy: 0.6650 - val_loss: 2.6388 - val_categorical_accuracy: 0.2454\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 880ms/step - loss: 0.8529 - categorical_accuracy: 0.6024 - val_loss: 2.5072 - val_categorical_accuracy: 0.3235\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.6334 - categorical_accuracy: 0.6818 - val_loss: 2.9687 - val_categorical_accuracy: 0.2675\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 536s 880ms/step - loss: 0.6259 - categorical_accuracy: 0.6781 - val_loss: 2.8853 - val_categorical_accuracy: 0.2886\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.6236 - categorical_accuracy: 0.6877 - val_loss: 2.8257 - val_categorical_accuracy: 0.1287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.27      0.13       190\n",
            "         1.0       0.18      0.13      0.15       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.17      0.45      0.25       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.43      0.12      0.19        76\n",
            "         6.0       0.94      0.52      0.67       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.05      0.46      0.09       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.13      2708\n",
            "   macro avg       0.18      0.20      0.15      2708\n",
            "weighted avg       0.11      0.13      0.10      2708\n",
            "\n",
            "0.1951356969544379\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 367ms/step - loss: 1.2159 - categorical_accuracy: 0.4541 - val_loss: 2.1646 - val_categorical_accuracy: 0.2638\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.0292 - categorical_accuracy: 0.4957 - val_loss: 2.2515 - val_categorical_accuracy: 0.2537\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.0081 - categorical_accuracy: 0.5090 - val_loss: 2.2440 - val_categorical_accuracy: 0.2684\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.9991 - categorical_accuracy: 0.5054 - val_loss: 2.3017 - val_categorical_accuracy: 0.2482\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 0.9822 - categorical_accuracy: 0.5109 - val_loss: 2.2757 - val_categorical_accuracy: 0.2555\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 0.9708 - categorical_accuracy: 0.5145 - val_loss: 2.2754 - val_categorical_accuracy: 0.2564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06       190\n",
            "         1.0       0.25      0.14      0.18       173\n",
            "         2.0       0.06      0.14      0.09       135\n",
            "         3.0       0.19      0.24      0.21       216\n",
            "         4.0       0.53      0.20      0.29      1036\n",
            "         5.0       0.42      0.11      0.17        76\n",
            "         6.0       0.78      0.71      0.74       195\n",
            "         7.0       0.12      0.21      0.16       290\n",
            "         8.0       0.09      0.23      0.13       139\n",
            "         9.0       0.20      0.45      0.27       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.28      0.25      0.23      2708\n",
            "weighted avg       0.35      0.25      0.26      2708\n",
            "\n",
            "0.24538399803019706\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 569s 893ms/step - loss: 0.7703 - categorical_accuracy: 0.5846 - val_loss: 2.5038 - val_categorical_accuracy: 0.2767\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.5538 - categorical_accuracy: 0.6744 - val_loss: 2.7458 - val_categorical_accuracy: 0.2858\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 0.4523 - categorical_accuracy: 0.7268 - val_loss: 2.7418 - val_categorical_accuracy: 0.2987\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 0.3836 - categorical_accuracy: 0.7657 - val_loss: 2.9142 - val_categorical_accuracy: 0.3015\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 0.3323 - categorical_accuracy: 0.7907 - val_loss: 2.9112 - val_categorical_accuracy: 0.3153\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.2907 - categorical_accuracy: 0.8165 - val_loss: 3.0451 - val_categorical_accuracy: 0.3254\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.07      0.11       190\n",
            "         1.0       0.15      0.06      0.08       173\n",
            "         2.0       0.07      0.12      0.09       135\n",
            "         3.0       0.20      0.23      0.21       216\n",
            "         4.0       0.58      0.41      0.48      1036\n",
            "         5.0       0.55      0.08      0.14        76\n",
            "         6.0       0.83      0.71      0.76       195\n",
            "         7.0       0.13      0.27      0.18       290\n",
            "         8.0       0.11      0.19      0.14       139\n",
            "         9.0       0.24      0.31      0.27       258\n",
            "\n",
            "    accuracy                           0.31      2708\n",
            "   macro avg       0.31      0.24      0.25      2708\n",
            "weighted avg       0.38      0.31      0.33      2708\n",
            "\n",
            "0.24465893332573913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_transfer_learning[5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cc8b3C-m1Gk",
        "outputId": "e7c9cb69-bb2a-4fc5-f3ee-eecf897ee839"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24114452614265702, 0.2493581581035141, 0.24538399803019706]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning[5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTmbyH72mzri",
        "outputId": "90cc55a3-e5a4-43b6-80f0-1c01ab1a253d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2591786542521592, 0.1951356969544379, 0.24465893332573913]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.3]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDd6MeYn7R9E",
        "outputId": "467601a2-efd8-4b8f-dce7-b1902fa82c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 366ms/step - loss: 0.3530 - categorical_accuracy: 0.8181 - val_loss: 4.6522 - val_categorical_accuracy: 0.3079\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2819 - categorical_accuracy: 0.8460 - val_loss: 4.7302 - val_categorical_accuracy: 0.3235\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2534 - categorical_accuracy: 0.8581 - val_loss: 5.0115 - val_categorical_accuracy: 0.3502\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2191 - categorical_accuracy: 0.8698 - val_loss: 4.8203 - val_categorical_accuracy: 0.3373\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2138 - categorical_accuracy: 0.8627 - val_loss: 4.8558 - val_categorical_accuracy: 0.3125\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2100 - categorical_accuracy: 0.8683 - val_loss: 4.7053 - val_categorical_accuracy: 0.3281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.08      0.10       190\n",
            "         1.0       0.17      0.06      0.09       173\n",
            "         2.0       0.06      0.10      0.08       135\n",
            "         3.0       0.19      0.20      0.19       216\n",
            "         4.0       0.56      0.39      0.46      1036\n",
            "         5.0       0.55      0.08      0.14        76\n",
            "         6.0       0.84      0.69      0.76       195\n",
            "         7.0       0.13      0.27      0.18       290\n",
            "         8.0       0.12      0.24      0.16       139\n",
            "         9.0       0.24      0.29      0.26       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.30      0.24      0.24      2708\n",
            "weighted avg       0.37      0.30      0.32      2708\n",
            "\n",
            "0.24068599126812157\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 892ms/step - loss: 0.2203 - categorical_accuracy: 0.8519 - val_loss: 5.0364 - val_categorical_accuracy: 0.3125\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1989 - categorical_accuracy: 0.8660 - val_loss: 5.1490 - val_categorical_accuracy: 0.3254\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1790 - categorical_accuracy: 0.8784 - val_loss: 5.3023 - val_categorical_accuracy: 0.3364\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1582 - categorical_accuracy: 0.8874 - val_loss: 5.3419 - val_categorical_accuracy: 0.3272\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1584 - categorical_accuracy: 0.8960 - val_loss: 5.2012 - val_categorical_accuracy: 0.3566\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1483 - categorical_accuracy: 0.9050 - val_loss: 4.9733 - val_categorical_accuracy: 0.3529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.10      0.12       190\n",
            "         1.0       0.20      0.06      0.10       173\n",
            "         2.0       0.07      0.09      0.08       135\n",
            "         3.0       0.20      0.17      0.18       216\n",
            "         4.0       0.56      0.47      0.51      1036\n",
            "         5.0       0.55      0.08      0.14        76\n",
            "         6.0       0.83      0.70      0.76       195\n",
            "         7.0       0.14      0.24      0.17       290\n",
            "         8.0       0.11      0.22      0.15       139\n",
            "         9.0       0.23      0.28      0.25       258\n",
            "\n",
            "    accuracy                           0.33      2708\n",
            "   macro avg       0.30      0.24      0.25      2708\n",
            "weighted avg       0.37      0.33      0.34      2708\n",
            "\n",
            "0.24184874191585165\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 368ms/step - loss: 0.4913 - categorical_accuracy: 0.8213 - val_loss: 3.3338 - val_categorical_accuracy: 0.3557\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1803 - categorical_accuracy: 0.9095 - val_loss: 3.8188 - val_categorical_accuracy: 0.3548\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1569 - categorical_accuracy: 0.9206 - val_loss: 3.9239 - val_categorical_accuracy: 0.3686\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1406 - categorical_accuracy: 0.9256 - val_loss: 4.1161 - val_categorical_accuracy: 0.3667\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1359 - categorical_accuracy: 0.9300 - val_loss: 4.1055 - val_categorical_accuracy: 0.3750\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1337 - categorical_accuracy: 0.9325 - val_loss: 4.2220 - val_categorical_accuracy: 0.3612\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.08      0.09       190\n",
            "         1.0       0.22      0.08      0.11       173\n",
            "         2.0       0.08      0.08      0.08       135\n",
            "         3.0       0.18      0.18      0.18       216\n",
            "         4.0       0.56      0.54      0.55      1036\n",
            "         5.0       0.60      0.08      0.14        76\n",
            "         6.0       0.85      0.70      0.77       195\n",
            "         7.0       0.14      0.22      0.17       290\n",
            "         8.0       0.11      0.24      0.15       139\n",
            "         9.0       0.25      0.21      0.23       258\n",
            "\n",
            "    accuracy                           0.35      2708\n",
            "   macro avg       0.31      0.24      0.25      2708\n",
            "weighted avg       0.38      0.35      0.35      2708\n",
            "\n",
            "0.24152452827204512\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 572s 892ms/step - loss: 0.4364 - categorical_accuracy: 0.7943 - val_loss: 3.5063 - val_categorical_accuracy: 0.3244\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 2.0401 - categorical_accuracy: 0.2666 - val_loss: 2.3408 - val_categorical_accuracy: 0.0947\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.9899 - categorical_accuracy: 0.2219 - val_loss: 2.0768 - val_categorical_accuracy: 0.1985\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.7435 - categorical_accuracy: 0.2836 - val_loss: 2.0746 - val_categorical_accuracy: 0.2206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.15      0.28      0.20       173\n",
            "         2.0       0.05      0.01      0.02       135\n",
            "         3.0       0.11      0.23      0.15       216\n",
            "         4.0       0.39      0.13      0.20      1036\n",
            "         5.0       0.41      0.12      0.18        76\n",
            "         6.0       0.76      0.76      0.76       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.10      0.12      0.11       139\n",
            "         9.0       0.14      0.62      0.23       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.21      0.23      0.19      2708\n",
            "weighted avg       0.26      0.21      0.19      2708\n",
            "\n",
            "0.22925599574452962\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 368ms/step - loss: 1.5823 - categorical_accuracy: 0.2958 - val_loss: 2.1996 - val_categorical_accuracy: 0.1921\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 1.4550 - categorical_accuracy: 0.3300 - val_loss: 2.2422 - val_categorical_accuracy: 0.1958\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 1.4314 - categorical_accuracy: 0.3341 - val_loss: 2.3209 - val_categorical_accuracy: 0.1847\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 1.4306 - categorical_accuracy: 0.3300 - val_loss: 2.2992 - val_categorical_accuracy: 0.1737\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 359ms/step - loss: 1.4195 - categorical_accuracy: 0.3294 - val_loss: 2.2737 - val_categorical_accuracy: 0.1921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.07      0.10       190\n",
            "         1.0       0.17      0.20      0.18       173\n",
            "         2.0       0.06      0.21      0.10       135\n",
            "         3.0       0.12      0.14      0.13       216\n",
            "         4.0       0.51      0.07      0.12      1036\n",
            "         5.0       0.28      0.12      0.17        76\n",
            "         6.0       0.77      0.75      0.76       195\n",
            "         7.0       0.13      0.09      0.11       290\n",
            "         8.0       0.08      0.30      0.13       139\n",
            "         9.0       0.15      0.34      0.21       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.24      0.23      0.20      2708\n",
            "weighted avg       0.32      0.18      0.18      2708\n",
            "\n",
            "0.2303130166302793\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 891ms/step - loss: 1.3501 - categorical_accuracy: 0.3499 - val_loss: 2.3684 - val_categorical_accuracy: 0.1967\n",
            "Epoch 2/6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resume from the last checkpoint"
      ],
      "metadata": {
        "id": "IbueZKWW6sH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters.append((1e-3, 1e-6, 0.3))\n",
        "seen_parameters.append((1e-4, 1e-5, 0.3))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIekcZL46rjk",
        "outputId": "0bf93168-7782-45e2-f187-9f3fb172fb64"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5),\n",
              " (0.001, 1e-06, 0.3),\n",
              " (0.0001, 1e-05, 0.3)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters.remove((0.0001, 1e-06, 0.3))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teTQtELP8TG3",
        "outputId": "535216c5-a65c-44bd-cd61-e5110b98f620"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5),\n",
              " (0.001, 1e-06, 0.3),\n",
              " (0.0001, 1e-05, 0.3)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar = {}\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []"
      ],
      "metadata": {
        "id": "3HsY4Csi7U77"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.3]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu4WBwkB7H0_",
        "outputId": "797094b6-69f4-4eba-e4a4-111f762879ee"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 418s 648ms/step - loss: 2.3861 - categorical_accuracy: 0.1485 - val_loss: 2.1801 - val_categorical_accuracy: 0.1912\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 390s 640ms/step - loss: 2.1133 - categorical_accuracy: 0.2192 - val_loss: 2.0884 - val_categorical_accuracy: 0.2270\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.9941 - categorical_accuracy: 0.2608 - val_loss: 2.0360 - val_categorical_accuracy: 0.2629\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 389s 640ms/step - loss: 1.9020 - categorical_accuracy: 0.2973 - val_loss: 1.9806 - val_categorical_accuracy: 0.2785\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.8229 - categorical_accuracy: 0.3197 - val_loss: 1.9525 - val_categorical_accuracy: 0.3024\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.7614 - categorical_accuracy: 0.3305 - val_loss: 1.9242 - val_categorical_accuracy: 0.3107\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.19      0.17       190\n",
            "         1.0       0.18      0.38      0.24       173\n",
            "         2.0       0.09      0.10      0.09       135\n",
            "         3.0       0.13      0.19      0.16       216\n",
            "         4.0       0.64      0.33      0.44      1036\n",
            "         5.0       0.18      0.38      0.25        76\n",
            "         6.0       0.54      0.81      0.65       195\n",
            "         7.0       0.16      0.07      0.09       290\n",
            "         8.0       0.10      0.12      0.10       139\n",
            "         9.0       0.24      0.37      0.29       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.24      0.29      0.25      2708\n",
            "weighted avg       0.37      0.30      0.31      2708\n",
            "\n",
            "0.29257651143912194\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 986s 2s/step - loss: 1.7809 - categorical_accuracy: 0.3281 - val_loss: 1.9469 - val_categorical_accuracy: 0.2978\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7997 - categorical_accuracy: 0.3209 - val_loss: 1.9459 - val_categorical_accuracy: 0.2886\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8179 - categorical_accuracy: 0.3180 - val_loss: 1.9257 - val_categorical_accuracy: 0.2969\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7903 - categorical_accuracy: 0.3312 - val_loss: 1.9016 - val_categorical_accuracy: 0.3006\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7939 - categorical_accuracy: 0.3264 - val_loss: 1.9550 - val_categorical_accuracy: 0.2932\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7994 - categorical_accuracy: 0.3276 - val_loss: 1.9756 - val_categorical_accuracy: 0.2757\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.18      0.18       190\n",
            "         1.0       0.18      0.32      0.23       173\n",
            "         2.0       0.08      0.10      0.09       135\n",
            "         3.0       0.17      0.24      0.20       216\n",
            "         4.0       0.66      0.35      0.46      1036\n",
            "         5.0       0.14      0.36      0.20        76\n",
            "         6.0       0.55      0.82      0.66       195\n",
            "         7.0       0.12      0.04      0.07       290\n",
            "         8.0       0.11      0.12      0.11       139\n",
            "         9.0       0.20      0.34      0.25       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.24      0.29      0.24      2708\n",
            "weighted avg       0.37      0.30      0.31      2708\n",
            "\n",
            "0.2871389490893207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rndLTvgufxm-",
        "outputId": "14590f37-5a50-45a8-a146-629ad61d2bc9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2871389490893207]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.4]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z75mtdrI7Tmg",
        "outputId": "fbfa7391-d03d-4f1b-b55a-5e8ba6a91aaa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 418s 648ms/step - loss: 2.5535 - categorical_accuracy: 0.1344 - val_loss: 2.2163 - val_categorical_accuracy: 0.1912\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 2.2077 - categorical_accuracy: 0.1970 - val_loss: 2.1123 - val_categorical_accuracy: 0.2022\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 390s 640ms/step - loss: 2.0754 - categorical_accuracy: 0.2191 - val_loss: 2.0452 - val_categorical_accuracy: 0.2197\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 390s 640ms/step - loss: 1.9700 - categorical_accuracy: 0.2524 - val_loss: 2.0080 - val_categorical_accuracy: 0.2215\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.9136 - categorical_accuracy: 0.2634 - val_loss: 1.9795 - val_categorical_accuracy: 0.2307\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.8342 - categorical_accuracy: 0.2964 - val_loss: 1.9442 - val_categorical_accuracy: 0.2518\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.33      0.23       190\n",
            "         1.0       0.17      0.31      0.22       173\n",
            "         2.0       0.08      0.10      0.09       135\n",
            "         3.0       0.14      0.07      0.10       216\n",
            "         4.0       0.64      0.21      0.32      1036\n",
            "         5.0       0.15      0.53      0.24        76\n",
            "         6.0       0.54      0.81      0.64       195\n",
            "         7.0       0.14      0.04      0.06       290\n",
            "         8.0       0.12      0.15      0.14       139\n",
            "         9.0       0.18      0.44      0.26       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.23      0.30      0.23      2708\n",
            "weighted avg       0.36      0.26      0.25      2708\n",
            "\n",
            "0.2986264741482065\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_5/albert/pooler/kernel:0', 'tf_albert_model_5/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_5/albert/pooler/kernel:0', 'tf_albert_model_5/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 988s 2s/step - loss: 1.8312 - categorical_accuracy: 0.2922 - val_loss: 1.9666 - val_categorical_accuracy: 0.2371\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8744 - categorical_accuracy: 0.2819 - val_loss: 1.9689 - val_categorical_accuracy: 0.2426\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 957s 2s/step - loss: 1.8781 - categorical_accuracy: 0.2731 - val_loss: 1.9869 - val_categorical_accuracy: 0.2491\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8775 - categorical_accuracy: 0.2720 - val_loss: 1.9427 - val_categorical_accuracy: 0.2702\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8841 - categorical_accuracy: 0.2818 - val_loss: 1.9828 - val_categorical_accuracy: 0.2399\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 955s 2s/step - loss: 1.8930 - categorical_accuracy: 0.2762 - val_loss: 1.9521 - val_categorical_accuracy: 0.2693\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.30      0.23       190\n",
            "         1.0       0.16      0.31      0.21       173\n",
            "         2.0       0.10      0.11      0.10       135\n",
            "         3.0       0.17      0.09      0.11       216\n",
            "         4.0       0.65      0.20      0.31      1036\n",
            "         5.0       0.13      0.50      0.21        76\n",
            "         6.0       0.50      0.83      0.63       195\n",
            "         7.0       0.10      0.03      0.04       290\n",
            "         8.0       0.13      0.16      0.14       139\n",
            "         9.0       0.18      0.43      0.26       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.23      0.30      0.22      2708\n",
            "weighted avg       0.37      0.26      0.25      2708\n",
            "\n",
            "0.29546834261073013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.5]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "id": "dd1WOoaE7VCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this result, ALBERT performs best at the dropout rate of ____."
      ],
      "metadata": {
        "id": "gaZxeBiu-l8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KFolds"
      ],
      "metadata": {
        "id": "tldC3z9k7eb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Xid_Xmask(X_origin):\n",
        "  Xids_train = np.zeros((X_origin.shape[0], SEQ_LEN))\n",
        "  Xmask_train = np.zeros((X_origin.shape[0], SEQ_LEN))\n",
        "\n",
        "  for i, lyric in enumerate(X_origin):\n",
        "    tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "    Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "  return Xids_train, Xmask_train"
      ],
      "metadata": {
        "id": "9IK2f7oI8yB5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_DROPOUT_RATE = "
      ],
      "metadata": {
        "id": "8iitxI-f_Ds-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies = []\n",
        "for i in range(1,5):\n",
        "  #step1: train, val, test preparation.\n",
        "  split0=splits[i]\n",
        "  split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "  split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "  #tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
        "  Xids_train, Xmask_train = get_Xid_Xmask(split0['X_train'])\n",
        "  Xids_test, Xmask_test = get_Xid_Xmask(split0['X_test'])\n",
        "\n",
        "  labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "  labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "  labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "  labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "  dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "  dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "  dataset_train = dataset_train.map(map_func)\n",
        "  dataset_test = dataset_test.map(map_func)\n",
        "\n",
        "  dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "  train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "  val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "  test = dataset_test.batch(16)\n",
        "\n",
        "  #step2: build a ALBERT model\n",
        "  input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "  mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "  embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "  X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "  X = tf.keras.layers.BatchNormalization()(X)\n",
        "  X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "  X = tf.keras.layers.Dropout(BEST_DROPOUT_RATE)(X)\n",
        "  X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "  y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "  model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "  model2.layers[2].trainable = False\n",
        "\n",
        "  #step2\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "  metrics = []\n",
        "  metrics.append(\n",
        "      tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "  model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "  #model2.summary() #Check trainable params increased.\n",
        "\n",
        "  #step3: transfer learning\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "  history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "  #step4: predict\n",
        "  y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "\n",
        "  #step5: fine tune\n",
        "  model2.layers[2].trainable = True\n",
        "\n",
        "  # It's important to recompile your model after you make any changes\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "  metrics = []\n",
        "  metrics.append(\n",
        "      tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "  model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "  history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "  y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "\n",
        "  del(model2)\n",
        "\n"
      ],
      "metadata": {
        "id": "lDs4ael07j9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unnecessary codes"
      ],
      "metadata": {
        "id": "kB5s7bSA7Y8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train), len(val), len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq1whv1tYsTD",
        "outputId": "f497aad4-98c0-40e1-f48e-4bece4704248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609 68 170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, transfer learning"
      ],
      "metadata": {
        "id": "oh7wwxGXVwbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "model2.summary() #Check trainable params increased."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk1v17d2V8pK",
        "outputId": "73b05a93-531e-4db3-f6f1-f41c20779250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  11683584   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 768),                                                           \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,789,546\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 11,685,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=1088"
      ],
      "metadata": {
        "id": "t8N7d7FpbcFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "\n",
        "#metrics = Metrics()\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])#metrics\n",
        "#metrics.get_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b1993b-016e-4853-aad0-d37b6bb27fbb",
        "id": "Qodzv_gGVyDU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 90s 128ms/step - loss: 2.1484 - categorical_accuracy: 0.2435 - val_loss: 1.9851 - val_categorical_accuracy: 0.2776\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 75s 124ms/step - loss: 1.8344 - categorical_accuracy: 0.3179 - val_loss: 1.9732 - val_categorical_accuracy: 0.2794\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 76s 124ms/step - loss: 1.6454 - categorical_accuracy: 0.3703 - val_loss: 1.9635 - val_categorical_accuracy: 0.2978\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 75s 124ms/step - loss: 1.4627 - categorical_accuracy: 0.4187 - val_loss: 2.0251 - val_categorical_accuracy: 0.3024\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 75s 124ms/step - loss: 1.2999 - categorical_accuracy: 0.4579 - val_loss: 2.1355 - val_categorical_accuracy: 0.2868\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 75s 124ms/step - loss: 1.1250 - categorical_accuracy: 0.5019 - val_loss: 2.1858 - val_categorical_accuracy: 0.3107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = split0[\"y_test\"].shape[0]\n",
        "TEST_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47883209-0b16-42fe-aca1-8066e66bad98",
        "id": "LxsdMGbnVyDV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2708"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_transfer_learning=get_balanced_accuracy(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b09985e3-9bb7-4e2c-f82b-0c0998e2c1fa",
        "id": "RZlTKmEMVyDV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.24      0.19       190\n",
            "         1.0       0.17      0.27      0.21       173\n",
            "         2.0       0.12      0.10      0.11       135\n",
            "         3.0       0.14      0.17      0.15       216\n",
            "         4.0       0.66      0.31      0.42      1036\n",
            "         5.0       0.13      0.17      0.15        76\n",
            "         6.0       0.54      0.72      0.62       195\n",
            "         7.0       0.14      0.07      0.09       290\n",
            "         8.0       0.09      0.25      0.13       139\n",
            "         9.0       0.19      0.28      0.23       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.23      0.26      0.23      2708\n",
            "weighted avg       0.37      0.28      0.29      2708\n",
            "\n",
            "0.25892839922093847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tuning with smaller learning rate"
      ],
      "metadata": {
        "id": "EstRo8XxBGr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base model\n",
        "#model.trainable = True\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "model2.summary() #Check trainable params increased."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZgKI4hVBSIj",
        "outputId": "f340b214-ddc0-4803-a3fd-70778f222ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_roberta_model[0][0]']       \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 124,750,058\n",
            "Non-trainable params: 1,536\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics = Metrics()\n",
        "history = model2.fit(train2, validation_data=val2, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])#metrics\n",
        "#metrics.get_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc0EvIGjIL3D",
        "outputId": "999dbb02-2440-473a-b127-20096c678bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 203s 307ms/step - loss: 1.7488 - categorical_accuracy: 0.3503 - val_loss: 1.9209 - val_categorical_accuracy: 0.3309\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.6219 - categorical_accuracy: 0.3758 - val_loss: 1.8664 - val_categorical_accuracy: 0.3373\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.5014 - categorical_accuracy: 0.4157 - val_loss: 1.8434 - val_categorical_accuracy: 0.2960\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.4113 - categorical_accuracy: 0.4380 - val_loss: 1.8316 - val_categorical_accuracy: 0.3373\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.2980 - categorical_accuracy: 0.4698 - val_loss: 1.8991 - val_categorical_accuracy: 0.3419\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.2123 - categorical_accuracy: 0.5004 - val_loss: 1.7828 - val_categorical_accuracy: 0.3631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_balanced_accuracy(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2oTAC3CIQas",
        "outputId": "64bcd94a-3a10-4ed9-c894-f57b5bbffc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.23      0.24       190\n",
            "         1.0       0.19      0.32      0.24       173\n",
            "         2.0       0.09      0.25      0.13       135\n",
            "         3.0       0.25      0.20      0.22       216\n",
            "         4.0       0.74      0.41      0.53      1036\n",
            "         5.0       0.23      0.41      0.30        76\n",
            "         6.0       0.65      0.90      0.76       195\n",
            "         7.0       0.14      0.01      0.01       290\n",
            "         8.0       0.13      0.23      0.17       139\n",
            "         9.0       0.27      0.47      0.34       258\n",
            "\n",
            "    accuracy                           0.36      2708\n",
            "   macro avg       0.30      0.34      0.29      2708\n",
            "weighted avg       0.44      0.36      0.36      2708\n",
            "\n",
            "0.34310539549600694\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DWL5DlwVTHgV",
        "hWxfNJqYBfjD",
        "nONmunMa_h7T",
        "hb0KcNXhbUSN",
        "oylD4vpEYC_m",
        "wr-sII815ZQY",
        "tldC3z9k7eb3"
      ],
      "machine_shape": "hm",
      "name": "week15_ALBERT_large_baseline_keras.ipynb",
      "provenance": [],
      "mount_file_id": "1GBA8Fqnm539nmtGxpqfHLZTiRfHsS80x",
      "authorship_tag": "ABX9TyMdkPjMXpMrzp1vjjkx8Pjz",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "662d0f403d1e4dfeb6fc29be94f50198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f0af31782e5435581e80666c77478bd",
              "IPY_MODEL_53abe4f95cf345869a3b6f44f96b1520",
              "IPY_MODEL_6556acea07544f8c8f414265f2d87511"
            ],
            "layout": "IPY_MODEL_69713da665c64ba8b168483309af40e8"
          }
        },
        "8f0af31782e5435581e80666c77478bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d139056dee4493abaa1e2757840091b",
            "placeholder": "​",
            "style": "IPY_MODEL_0803723664024e8b8e036b3886110483",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "53abe4f95cf345869a3b6f44f96b1520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4aaf7d3d784d08973922bb7f50bf07",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7d2fb18cb0748a69be07610ec5be7d3",
            "value": 526681800
          }
        },
        "6556acea07544f8c8f414265f2d87511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc37a448c8c48c1a5910f19a3c06730",
            "placeholder": "​",
            "style": "IPY_MODEL_1acbc29d6f914422883ae875cad5fef5",
            "value": " 502M/502M [00:08&lt;00:00, 64.3MB/s]"
          }
        },
        "69713da665c64ba8b168483309af40e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d139056dee4493abaa1e2757840091b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0803723664024e8b8e036b3886110483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c4aaf7d3d784d08973922bb7f50bf07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d2fb18cb0748a69be07610ec5be7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecc37a448c8c48c1a5910f19a3c06730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acbc29d6f914422883ae875cad5fef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4959f69a9ef54f03814b9a97ffbfce93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5b6dd20508d4d18a6fffdf813166957",
              "IPY_MODEL_7fa4898e5b184684a429c5c7ff430c29",
              "IPY_MODEL_9005cb8f77f64ebea7d9114decc9536b"
            ],
            "layout": "IPY_MODEL_a427b331158c4f1eac7d0df94a66063b"
          }
        },
        "c5b6dd20508d4d18a6fffdf813166957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f49d0f4745475eb79a00b800391ac6",
            "placeholder": "​",
            "style": "IPY_MODEL_069b4baf890d46bdb5f2d17764ef20e1",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "7fa4898e5b184684a429c5c7ff430c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e81535265d44db9d275770e3bf8d37",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1142ae2ce9543e7929408dca1367677",
            "value": 760289
          }
        },
        "9005cb8f77f64ebea7d9114decc9536b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce14a81fd4e8402183c340b4973746e8",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c534b37f2e403486a0fdcffe0e0629",
            "value": " 742k/742k [00:00&lt;00:00, 2.48MB/s]"
          }
        },
        "a427b331158c4f1eac7d0df94a66063b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f49d0f4745475eb79a00b800391ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069b4baf890d46bdb5f2d17764ef20e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64e81535265d44db9d275770e3bf8d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1142ae2ce9543e7929408dca1367677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce14a81fd4e8402183c340b4973746e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c534b37f2e403486a0fdcffe0e0629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62572e42db14e5e9af9c2758c54454d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a515fca234754cbb98ccf65a3781e47e",
              "IPY_MODEL_8be186e581f047fea6ce883da1d4c0b1",
              "IPY_MODEL_42f7832394364b5fb9b8c991fe5aa539"
            ],
            "layout": "IPY_MODEL_ff602015a67b4d518aa80d463f7e8f92"
          }
        },
        "a515fca234754cbb98ccf65a3781e47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_617b3f1beab849938c57eb129b55deb9",
            "placeholder": "​",
            "style": "IPY_MODEL_791d6d82fe30472daafa321f4eb0c290",
            "value": "Downloading config.json: 100%"
          }
        },
        "8be186e581f047fea6ce883da1d4c0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de52522216948b29f9f1d79c0315877",
            "max": 685,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a82895b5f5c54a0ea2c301f4eedaf27c",
            "value": 685
          }
        },
        "42f7832394364b5fb9b8c991fe5aa539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d272255b0445038196f2b4d0ec9e5c",
            "placeholder": "​",
            "style": "IPY_MODEL_56f8aae43cfd401a9dee6a968cbb3401",
            "value": " 685/685 [00:00&lt;00:00, 28.0kB/s]"
          }
        },
        "ff602015a67b4d518aa80d463f7e8f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "617b3f1beab849938c57eb129b55deb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791d6d82fe30472daafa321f4eb0c290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de52522216948b29f9f1d79c0315877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a82895b5f5c54a0ea2c301f4eedaf27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37d272255b0445038196f2b4d0ec9e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f8aae43cfd401a9dee6a968cbb3401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}